{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN and LSTM\n",
    "#### By MMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils import *\n",
    "import random\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 19909 total characters and 27 unique characters in your data.\n"
     ]
    }
   ],
   "source": [
    "data = open('data/dinos.txt', 'r').read()\n",
    "data = data.lower()\n",
    "chars = list(set(data))\n",
    "data_size, vocab_size = len(data), len(chars)\n",
    "print('There are %d total characters and %d unique characters in your data.' % (data_size, vocab_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating dictionaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '\\n', 1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z'}\n"
     ]
    }
   ],
   "source": [
    "char_to_ix = {ch: i for i, ch in enumerate(sorted(chars))}\n",
    "ix_to_char = {i: ch for i, ch in enumerate(sorted(chars))}\n",
    "print(ix_to_char)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clipping Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clip(gradients, maxValue):\n",
    "    \n",
    "    dWaa, dWax, dWya, db, dby = gradients['dWaa'], gradients['dWax'], gradients['dWya'],\\\n",
    "                                gradients['db'], gradients['dby']\n",
    "   \n",
    "    # clip to mitigate exploding gradients, loop over [dWax, dWaa, dWya, db, dby]. (≈2 lines)\n",
    "    for gradient in [dWax, dWaa, dWya, db, dby]:\n",
    "        np.clip(gradient, a_min=-1 * maxValue, a_max=maxValue, out=gradient)\n",
    "    \n",
    "    gradients = {\"dWaa\": dWaa, \"dWax\": dWax, \"dWya\": dWya, \"db\": db, \"dby\": dby}\n",
    "    \n",
    "    return gradients\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(parameters, char_to_ix, seed):\n",
    "\n",
    "    # Retrieve parameters and relevant shapes from \"parameters\" dictionary\n",
    "    Waa, Wax, Wya, by, b = parameters['Waa'], parameters['Wax'], parameters['Wya'], \\\n",
    "                           parameters['by'], parameters['b']\n",
    "    vocab_size = by.shape[0]\n",
    "    n_a = Waa.shape[1]\n",
    "\n",
    "    # Step 1: Create the one-hot vector x for the first character (initializing the sequence generation). (≈1 line)\n",
    "    x = np.zeros(vocab_size)\n",
    "    x = np.reshape(x, (vocab_size, 1))\n",
    "    # Step 1': Initialize a_prev as zeros (≈1 line)\n",
    "    a_prev = np.zeros(n_a)\n",
    "    a_prev = np.reshape(a_prev, (n_a, 1))\n",
    "    \n",
    "    # Create an empty list of indices, this is the list which will contain the list of indices of the characters to generate (≈1 line)\n",
    "    indices = []\n",
    "\n",
    "    # Idx is a flag to detect a newline character, we initialize it to -1\n",
    "    idx = -1\n",
    "\n",
    "    # Loop over time-steps t. At each time-step, sample a character from a probability distribution and append \n",
    "    # its index to \"indices\". We'll stop if we reach 50 characters (which should be very unlikely with a well \n",
    "    # trained model), which helps debugging and prevents entering an infinite loop. \n",
    "    counter = 0\n",
    "    newline_character = char_to_ix['\\n']\n",
    "\n",
    "    while idx != newline_character and counter != 50:\n",
    "        # Step 2: Forward propagate x using the equations (1), (2) and (3)\n",
    "        a = np.tanh(np.matmul(Wax, x) + np.matmul(Waa, a_prev) + b)\n",
    "        z = np.matmul(Wya, a) + by\n",
    "        y = softmax(z)\n",
    "        y = y.flatten()\n",
    "\n",
    "        # for grading purposes\n",
    "        np.random.seed(counter + seed)\n",
    "\n",
    "        # Step 3: Sample the index of a character within the vocabulary from the probability distribution y\n",
    "        idx = np.random.choice(27, p=y)\n",
    "\n",
    "        # Append the index to \"indices\"\n",
    "        indices.append(idx)\n",
    "\n",
    "        # Step 4: Overwrite the input character as the one corresponding to the sampled index.\n",
    "        x = np.zeros(27)\n",
    "        x = np.reshape(x, (vocab_size, 1))\n",
    "        x[idx] = 1\n",
    "\n",
    "        # Update \"a_prev\" to be \"a\"\n",
    "        a_prev = a\n",
    "\n",
    "        # for grading purposes\n",
    "        seed += 1\n",
    "        counter += 1\n",
    "\n",
    "    if counter == 50:\n",
    "        indices.append(char_to_ix['\\n'])\n",
    "\n",
    "    return indices\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimize(X, Y, a_prev, parameters, learning_rate = 0.01):\n",
    "    # Forward propagate through time (≈1 line)\n",
    "    loss, cache = rnn_forward(X, Y, a_prev, parameters, vocab_size)\n",
    "    \n",
    "    # Backpropagate through time (≈1 line)\n",
    "    gradients, a = rnn_backward(X, Y, parameters, cache)\n",
    "    \n",
    "    # Clip your gradients between -5 (min) and 5 (max) (≈1 line)\n",
    "    gradients = clip(gradients, 5)\n",
    "    \n",
    "    # Update parameters (≈1 line)\n",
    "    parameters = update_parameters(parameters, gradients, learning_rate)\n",
    "    \n",
    "    return loss, gradients, a[len(X)-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3.2 - Training the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(data, ix_to_char, char_to_ix, num_iterations = 16000, n_a = 50, dino_names = 10, vocab_size = 27):\n",
    "    # Retrieve n_x and n_y from vocab_size\n",
    "    n_x, n_y = vocab_size, vocab_size\n",
    "    \n",
    "    # Initialize parameters\n",
    "    parameters = initialize_parameters(n_a, n_x, n_y)\n",
    "    \n",
    "    # Initialize loss (this is required because we want to smooth our loss, don't worry about it)\n",
    "    loss = get_initial_loss(vocab_size, dino_names)\n",
    "    \n",
    "    # Build list of all dinosaur names (training examples).\n",
    "    with open(\"data/dinos.txt\") as f:\n",
    "        examples = f.readlines()\n",
    "    examples = [x.lower().strip() for x in examples]\n",
    "    \n",
    "    # Shuffle list of all dinosaur names\n",
    "    shuffle(examples)\n",
    "    \n",
    "    # Initialize the hidden state of your LSTM\n",
    "    a_prev = np.zeros((n_a, 1))\n",
    "    \n",
    "    # Optimization loop\n",
    "    iteration = []\n",
    "    losses = []\n",
    "    for j in range(num_iterations):\n",
    "        # Use the hint above to define one training example (X,Y) (≈ 2 lines)\n",
    "        index = j % len(examples)\n",
    "        X = [None] + [char_to_ix[ch] for ch in examples[index]] \n",
    "        Y = X[1:] + [char_to_ix[\"\\n\"]]\n",
    "        \n",
    "        # Perform one optimization step: Forward-prop -> Backward-prop -> Clip -> Update parameters\n",
    "        # Choose a learning rate of 0.01\n",
    "        curr_loss, gradients, a_prev = optimize(X, Y, a_prev, parameters, learning_rate=0.01)\n",
    "        \n",
    "        # Use a latency trick to keep the loss smooth. It happens here to accelerate the training.\n",
    "        loss = smooth(loss, curr_loss)\n",
    "\n",
    "        # Every 2000 Iteration, generate \"n\" characters thanks to sample() to check if the model is learning properly\n",
    "        if j % 100 == 0:\n",
    "            losses.append(loss)\n",
    "            iteration.append(j)\n",
    "            print('Iteration: %d, Loss: %f' % (j, loss) + '\\n')\n",
    "            \n",
    "            # The number of dinosaur names to print\n",
    "            seed = 0\n",
    "            for name in range(dino_names):\n",
    "                \n",
    "                # Sample indices and print them\n",
    "                sampled_indices = sample(parameters, char_to_ix, seed)\n",
    "                print_sample(sampled_indices, ix_to_char)\n",
    "                \n",
    "                seed += 1  # To get the same result for grading purposed, increment the seed by one. \n",
    "      \n",
    "            print('\\n')\n",
    "        \n",
    "    return parameters, iteration, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0, Loss: 32.978147\n\nNkzxwtdmfqoeyhsqwasjkjvu\nKneb\nKzxwtdmfqoeyhsqwasjkjvu\nNeb\nZxwtdmfqoeyhsqwasjkjvu\nEb\nXwtdmfqoeyhsqwasjkjvu\nB\nWtdmfqoeyhsqwasjkjvu\n\n\n\nIteration: 100, Loss: 33.583913\n\nOkyvusbndrodygsqu\nKoda\nKyvusbndrodygsqu\nOda\nYvusbndrodygsqu\nDa\nVusbndrodygsqu\nA\nUsbndrodygsqu\n\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 200, Loss: 34.117208\n\nOmxuusaocrqbwgsru\nKoca\nLxuusaocrqbwgsru\nOca\nXuusaocrqbwgsru\nCa\nUusaocrqbwgsru\nA\nUsaocrqbwgsru\n\n\n\nIteration: 300, Loss: 34.364073\n\nOmxuusaocrobvesru\nLoca\nLxuusaocrobvesru\nOca\nXuusaocrobvesru\nCa\nUusaocrobvesru\nA\nUsaocrobvesru\n\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 400, Loss: 34.378026\n\nOovutsaperpeunspuashnlus\nLog\nMwutsaperpeunspuashnlus\nOf\nXutsaperpeunspuashnlus\nDa\nUtsaperpeunspuashnlus\nA\nUs\n\n\n\nIteration: 500, Loss: 34.230955\n\nOnvusmembroluposoarincsoaltiyheaicaudam\nJog\nKwuslenarndunosoapkiisoaksaymaahaeuaal\nOg\nXusielcroluposoarincsoaltiyheaicaudam\nCa\nUskenarndunosoapkiisoaksaymaahaeuaal\nA\nUs\n\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 600, Loss: 33.934476\n\nNiwusdenasalunoslasapius\nIoh\nKxttraogos\nNaa\nXuseelbpogurusiarhiisn\nCa\nUseemcpogurusiarhiisn\nA\nTraogos\n\n\n\nIteration: 700, Loss: 33.589953\n\nOousos\nJnba\nLwttraoioravesauaurlisl\nOia\nXttraoioravesauaurlisl\nDa\nUsagmdoravesauaurlisl\nA\nTraoioravesauaurlisl\n\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 800, Loss: 33.198460\n\nNjxusajohoraveseudus\nJndaaesomacourus\nLxttrcoipohurusacroresiaosawlianaltahdaol\nOia\nXusajohoraveseudus\nDaaesomacourus\nUsajohoraveseudus\nA\nTrcoipohurusacroresiaosawlianaltahdaol\n\n\n\nIteration: 900, Loss: 32.744764\n\nNiwtsoerdoravhosoarhhhrranriyieamaitageaolafpbtolo\nIoia\nJxtsnbojopeveros\nNca\nXtsnbojopeveros\nDaaerur\nTtpdlcoravhosoarhhhrranriyieamaitageaolafpbtolopra\nA\nTogmbpoiuruseasaurus\n\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1000, Loss: 32.469113\n\nNiwtsicmdoravesaucus\nIolaagpsagapsaurosrur\nIxtsicmdoravesaucus\nNca\nXtsicmdoravesaucus\nDaaeslkaaosaurosrur\nTsicmdoravesaucus\nA\nTohidoraveros\n\n\n\nIteration: 1100, Loss: 32.080642\n\nNiwtsicierolurusaconelrqanpjyhealaktaheandagogsher\nIoka\nIxtsicierolurusaconelrqanpjyhealaktaheandagogshero\nNca\nXtsicierolurusaconelrqanpjyhealaktaheandagogsheros\nDaaerur\nTsicierolurusaconelrqanpjyhealaktaheandagogsheros\n\nA\nTohierolurusaconelrqanpjyhealaktaheandagogsheros\n\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1200, Loss: 31.764770\n\nNiwusalneromurushasaurus\nIola\nJxtrojleromurushasaurus\nNda\nXusalneromurushasaurus\nEc\nTrojleromurushasaurus\nA\nTokjdoraveros\n\n\n\nIteration: 1300, Loss: 31.418610\n\nNivusahjesanvisaugus\nIpca\nIwtroligoraverls\nNac\nXtroligoraverls\nCa\nTrokigoraverls\nA\nTolieronvfpos\n\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1400, Loss: 31.148398\n\nMhusetanaurus\nInac\nIxtos\nMab\nXtos\nCa\nTos\nA\nTogharoiupros\n\n\n\nIteration: 1500, Loss: 30.754794\n\nMivtosaurus\nInacaisgibansaurushuraxanosausipeonasaurus\nIwtosaurus\nMacaisfhacltisaurus\nXusanolnmaurusacrosaur\nCa\nTosaurus\nA\nTojidoravgosebroresa\n\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1600, Loss: 30.366657\n\nMhusgulurtnaveros\nHida\nIxtos\nMacaisgecantis\nXusagiepnavfosh\nBa\nTos\nA\nToin\n\n\n\nIteration: 1700, Loss: 30.163716\n\nMivtos\nHlecagpsahaus\nIwtos\nMca\nXusaljerolurtntasaurus\nCa\nTos\nA\nToiresanunpruconggroansawjialdetageblebdohtomorna\n\n\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1800, Loss: 29.864631\n\nMhusisaurus\nHiebaerus\nIwtos\nMacaisheeaptmqagius\nXusakidmkaurus\nBa\nTos\nA\nTolgbnnavgoshargelps\n\n\n\nIteration: 1900, Loss: 29.535456\n\nLhytosaurus\nHidaaerqcachushelgus\nHxtosaurus\nLacaisigachushelgus\nXuscapatolurusaconanos\nAbamosanaus\nTosaurus\nA\nTolehipaveris\n\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2000, Loss: 29.341883\n\nLgwsludomoraverntareneseansavgeamaltacganabdojtomo\nHicaafron\nHusisasauritgosiarelhos\nLacaislebansaurusapaeyalos\nXusbaneopaurus\nA\nTos\nA\nTohhapneuosaudus\n\n\n\nIteration: 2100, Loss: 29.114418\n\nLhxtprapdos\nHica\nHwtos\nMacajrsafaus\nXusajnesaqtesaulus\nA\nTos\nA\nSalicoraverltarangtoanthylcanagudalaneadoktonnhha\n\n\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2200, Loss: 28.849253\n\nMivusaerasanveros\nHnecahosabaus\nIwusibleromveros\nMca\nXusicidosaurus\nBa\nTos\nA\nTokldos\n\n\n\nIteration: 2300, Loss: 28.614464\n\nMiwusagojopcurus\nInda\nIwtos\nMca\nXusdandopcurus\nCa\nTos\nA\nTogkdopcurus\n\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2400, Loss: 28.283193\n\nLhvrosaurus\nHhacalosanaus\nHvrosaurus\nLacalosanaus\nXusedhapneupros\nAa\nTosaurus\nA\nSdanerndurtos\n\n\n\nIteration: 2500, Loss: 28.160095\n\nMivtos\nInecalps\nIwtosaurus\nMccakrus\nXusjciipolvcors\nCaagrsalatros\nTosaurus\nA\nSickgopdurasocrlilto\n\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2600, Loss: 27.903179\n\nNivushingosaurus\nIpedahus\nIvusiciesausaurur\nNca\nXusiciesausaurur\nCaahusanaus\nTrolomosaurus\nA\nSicieronwgusiarinitobosaurur\n\n\n\nIteration: 2700, Loss: 27.818308\n\nNivusicherolurjps\nInecahps\nIvusleoloravhusacrrelps\nNca\nXusncherolvgosocrus\nCaaertf\nToranernctisaunus\nA\nTogleronurtos\n\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2800, Loss: 27.646488\n\nNivusegndopaurus\nInda\nJytorancor\nNca\nXusldngoravgosharilisfanrcyng\nCa\nTorangos\nA\nSiciionavhorocona\n\n\n\nIteration: 2900, Loss: 27.509703\n\nMhytosaurus\nInacalosaurus\nIwtosaurus\nMacalosaurus\nXusicherokuroseconggrobisaurup\nCa\nTosaurus\nA\nShandoravgoseconggrobisaurup\n\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3000, Loss: 27.399510\n\nLivushenerlaunsaupus\nInca\nIvusichirictisaurus\nLecakton\nWusichipieupros\nBa\nTorandos\nA\nTokiepmcunosiariictoanthyihanaluden\n\n\n\nIteration: 3100, Loss: 27.133209\n\nLivusarrascesaurupnggeskanthyndanaluialaphalomtons\nHicaaltopa\nIvusanparonvhosharengus\nLacalrus\nWtoraonosaurus\nAcalrus\nTorangosaurus\nA\nSdandoraurusacrosauraptous\n\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3200, Loss: 26.951518\n\nMgysrupidor\nIncabasmur\nIvtromharkaurus\nMacalpsanastiragmus\nWusmandoraveritaraphus\nBaaerpeechresaurus\nToraperidthisocrisaur\nA\nSiciericsaurupkiiisebrustheamantadja\n\n\n\nIteration: 3300, Loss: 26.859646\n\nNgytos\nInecalps\nIvuseendor\nNcaahropa\nWuslaneronurus\nCaagosateus\nTorapcoraurus\nA\nTolieps\n\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3400, Loss: 26.708924\n\nMixusiangopauosaupus\nIngaagosas\nIvusjangopauosaupus\nMacairomaansaurus\nXusmangoohunosiangiisianonyliaices\nCa\nTorangopauosauqus\nA\nToengopauosaupus\n\n\n\nIteration: 3500, Loss: 26.551155\n\nMevushanesausasaukus\nImacalosaurus\nIvushanesausasaukus\nMacaisiiachus\nWuskbidosaurus\nBaaerracarretengus\nTosaurus\nA\nTojharneunosanrlemtochusonebegetan\n\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3600, Loss: 26.479553\n\nNgyusndngopaurus\nImacaisiiabmurunanwiccyalosaurus\nIvusibiclohupros\nNca\nWusmbickoiunosdargheslansaurup\nCa\nToraperogveros\nA\nToengopaurus\n\n\n\nIteration: 3700, Loss: 26.334713\n\nNivtosaurus\nIngaahosam\nJytosaurus\nNgaagosan\nXusmaneronus\nCaaeron\nToraomos\nA\nTogngoravhosianilisacosaurur\n\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3800, Loss: 26.229155\n\nNivusbblepnhurosgaranitochurylialbcs\nInecalosaurus\nKytrodonnolurorrasaurus\nNecalosaurus\nWusmbicioithosiarcensiaosaurur\nCa\nTrodomosaurus\nA\nTojkeromurus\n\n\n\nIteration: 3900, Loss: 26.122507\n\nMevushanepoiunops\nInedagosaurus\nIvusicheorexasaunus\nMacalosaurus\nXusndieopaupoptapglisadrusaphandhucemang\nBaagosaurus\nTorangopaupoos\nA\nToingopaupoos\n\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 4000, Loss: 26.045318\n\nNivtroenchomvisaupus\nIndaafrus\nIvusiandor\nNdabcosatersaurus\nXusncherokurosiarchisnantovel\nCaaertga\nTrodoniolurlns\nA\nSiandoraviris\n\n\n\nIteration: 4100, Loss: 25.974621\n\nNgytoraomus\nInecalosaurus\nIvusnchiorawgsaunus\nNdaahprodaosaurus\nXusndonosaurus\nCaahosaurus\nTrodonoqaurus\nA\nTololopeverosaurus\n\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 4200, Loss: 25.865351\n\nNivstololopbwasfuconilsbanriylia\nInecalosaurus\nKxtosaurus\nNecalosaurus\nWusodomoqaurus\nCaagosaurus\nTorangosaurus\nA\nTololoravesaurus\n\n\n\nIteration: 4300, Loss: 25.750190\n\nNivrosaurus\nJlecalosaurus\nKxtosaurus\nNecalosaurus\nWuslandor\nDaagrona\nToraonosaurus\nA\nTolidor\n\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 4400, Loss: 25.772500\n\nNivtrollgosaurus\nInedalosaurus\nKytrojidor\nNecalosaurus\nXuspeonosaurus\nDaahosaurus\nTorapgor\nA\nTomidor\n\n\n\nIteration: 4500, Loss: 25.724850\n\nNhytrodonlomurusacrosaurkkusulianakueilandaeratonp\nInce\nKwuslchepleurops\nNecalskehaptosaurus\nWusnchernaups\nDa\nTpraokopaupontanghisianrhylganabueikanda\nA\nTolnboraveros\n\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 4600, Loss: 25.599403\n\nMiusps\nInca\nIusrognasaurus\nMacaisiecantisaurus\nWusmaneroitermocrigescansaururus\nCaaertehantis\nTorangosaurus\nA\nToglcinavhoskariidroansaururus\n\n\n\nIteration: 4700, Loss: 25.475790\n\nMivusichenlaumusacrimesjansavhechalucemanebaraus\nInca\nIvuskbicinaverlubrengus\nMacaisomabisaurus\nXusnchcinavermucongisbansavhecgbaua\nCaadosaunus\nTorapborawascsaphilus\nA\nTogkaribunoshaqelgus\n\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 4800, Loss: 25.392157\n\nMiustolidor\nInca\nIustolidor\nMacaiton\nXusogngronurusagrimerobitawataus\nCaagosaurus\nTorapgosaurus\nA\nToheisaurus\n\n\n\nIteration: 4900, Loss: 25.331054\n\nNivusanons\nInca\nIvusanonopaurus\nNebalosaurus\nXusiangosaurus\nCa\nTosaurus\nA\nToingosaurus\n\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 5000, Loss: 25.218667\n\nNivusarops\nImacalosaurus\nJyusiancholurhitas\nNebahosaurus\nXusianbosaurus\nDaaeropa\nTorasaurus\nA\nToidarantes\n\n\n\nIteration: 5100, Loss: 25.166093\n\nNgyusiandor\nKkacajpsapersaurus\nLytosaurus\nOhaahus\nWuskanerncurosaurus\nCaaerracarrathenus\nTrodonlomurosaurus\nA\nTojianonxatrulophisajrus\n\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 5200, Loss: 25.112899\n\nNgwtosaurus\nIngaahosaurus\nKwtqoinesaurus\nNgaahosaurus\nXusodonosaurus\nCaagosaurus\nTosaurus\nA\nTolonosaurus\n\n\n\nIteration: 5300, Loss: 25.104837\n\nOnytos\nLola\nLytoranaromups\nOla\nXutollcinaunoseconidos\nEdalptia\nTrodia\nA\nTolmanopterktalielto\n\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 5400, Loss: 25.029583\n\nOnyusedolophylosocrilishansaururaelycelaolalodrolo\nKnga\nLyusicheorevgoslarimdps\nOha\nXusicheopethtos\nDaagosaurus\nTrodolopetgosmarhigos\nA\nTodoloqeuroptaranitockussce\n\n\n\nIteration: 5500, Loss: 24.895561\n\nNgytrodomus\nImacalosaurus\nKytrodolopetdosiarangsoanthykabelatalialeceratonop\nNbaaerpfaanthus\nXuslandopaunosocongesmanthykabelatalialeceratonopl\nCaadosaurus\nTrodlarokursps\nA\nSlandonctisaurus\n\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 5600, Loss: 24.945093\n\nOnyusaurus\nJlecaiser\nKxuslangosaurus\nOla\nXusmangosaurus\nCaagrthacnus\nTrognatopthusaloprishanqiykechamuon\nA\nSndieopeveritaurus\n\n\n\nIteration: 5700, Loss: 24.902305\n\nOnyuslapgosaurus\nJlecahus\nLyuspaneromx\nOja\nXustapborawhusiateoptochustelaleitala\nCaaesteechusceliureeya\nTrodiciolyisauhus\nA\nToimasdeukoptasaurus\n\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 5800, Loss: 24.828353\n\nOnyuskendoraviros\nLoha\nLyussaurus\nOla\nXustendor\nEcaistehastes\nTorasaurus\nA\nTollepidus\n\n\n\nIteration: 5900, Loss: 24.822162\n\nOnxtos\nLnedakropa\nLyuslaphoraurus\nOla\nXusraphosaurus\nEcalosaurus\nTrognesaurus\nA\nTolnesaurus\n\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 6000, Loss: 24.827049\n\nOnuskoikaosaurus\nLicaaeshacarops\nLytosaurus\nOgaagosaurus\nWuspanasaurus\nDaadotedaniscelitiacycgosaurus\nTrodiasaurus\nA\nSocharaitasauous\n\n\n\nIteration: 6100, Loss: 24.710760\n\nOnvusaurus\nLlee\nLvushaolosaurus\nOlaahosaurus\nWusodon\nDaagror\nTromichonurosebrinatrasaurus\nA\nSmbjerootesaurus\n\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 6200, Loss: 24.660601\n\nNivtrogiainctiritaranitochusung\nKledaiton\nLystollaroptirks\nNecalrree\nXusraolorawerosaurus\nDaahosalartitan\nTroenchomygrnuangigrpantewcedia\nAaisphaclthuranus\nSnendoraverosaurus\n\n\n\nIteration: 6300, Loss: 24.587325\n\nMhxrosaurus\nInacalosaurus\nIussmbiankaterit\nMacakosaurus\nXusndichiateritargikus\nCaaeropa\nTorangosaurus\nA\nSjbichiauphosaurus\n\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 6400, Loss: 24.564086\n\nOnxushanesaurus\nLlca\nLytromelosaurus\nOlaaitop\nXusrapipletesaurus\nDaagosaurus\nTrognesaurus\nA\nTolichicurosbardhesraosaurus\n\n\n\nIteration: 6500, Loss: 24.491446\n\nOnyusehibor\nLode\nLyusiblerngyiros\nOfa\nYusoinatoptisaurus\nEcalosaurus\nTrodon\nA\nToinesaurus\n\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 6600, Loss: 24.468102\n\nNhysspanchoiter\nKicabcosaurus\nLytrodngopesaurulophitochonylebhalulanangalodromop\nNca\nXusichenmaurusanrangsiamusreiaeicreimaneceratops\nDaaeron\nTorangos\nA\nSibicin\n\n\n\nIteration: 6700, Loss: 24.464282\n\nOnyusaurus\nLoda\nLyushandor\nOgaakus\nXusnenfpolurins\nEdalosaurus\nTrodon\nA\nTodon\n\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 6800, Loss: 24.361383\n\nPhystomngosaurus\nLoma\nMytromleroptisaurus\nPeeaisphacisaurus\nXustephorhynosocriphosaurus\nEeaitria\nTrokngronus\nA\nTrephosaurus\nAltphacisaurus\n\n\nIteration: 6900, Loss: 24.373758\n\nOnyusanops\nLnecaclraccosaurus\nLytosaurus\nOia\nXusndheosaurus\nEcabosaurus\nTrodomnkatasaurus\nA\nTodomosaurus\nAgps\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 7000, Loss: 24.219825\n\nOnyusaurus\nKmacaisaurus\nLyuslbekopeurus\nOla\nXusodomosaurus\nCaaerracdosaurus\nTrodoniomunosialophos\nAagosaurus\nTogodon\nAlosaurus\n\n\nIteration: 7100, Loss: 24.302824\n\nOnwusoflernctisaurus\nLledalosaurus\nLytroinerlethorratloptraptourbamaluiemangaloernesa\nOlaalosaurus\nXusqeneoreurritargilus\nEealosaurus\nTrognermathorratoratrasrgymeceletendangalncorerlol\nA\nSognepneunortar\nAlosalerthreliuricuonmujatrongidontiongorephus\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 7200, Loss: 24.249878\n\nPhwusaurus\nLoma\nLytrong\nPfcalosaurus\nXuspdonosaurus\nEealosaurus\nTrolonosaurus\nA\nSohngps\nAlosaurus\n\n\nIteration: 7300, Loss: 24.292483\n\nOnuspolnerneweoptar\nLlecaisilachusheliurgax\nLustololopeurtosaurus\nOla\nXustandopeurusacrigishantixalapelucenaton\nEcakosaurus\nTorangosaurus\nAagrona\nTokeipigusaurisaurus\nAgosapasinogemus\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 7400, Loss: 24.265941\n\nOnvusiangopeuosaurus\nLoja\nLxusoenhopeuosaurus\nOlaagosaurus\nXustaoiosaurus\nEcalosaurus\nTroenhopgwdorocophiskansauruhiacs\nA\nToloiosaurus\nAhrona\n\n\nIteration: 7500, Loss: 24.289044\n\nOnvushamasaurus\nLledangteg\nLytrongasaurus\nOka\nXusraqgosaurus\nFaaerosaurus\nTrohidor\nA\nSodolosaurus\nAhropechusokenwtonychosaurus\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 7600, Loss: 24.259195\n\nOnvusibrinmethosiangikus\nLmee\nLvuskangondymusalroratraptotemanditanabonagoltopsa\nOma\nXustangosaurus\nEgalosaurus\nTrollernbvirosaurus\nAalosaurus\nTollernevhontarangus\nAlton\n\n\nIteration: 7700, Loss: 24.172644\n\nNgytosaurus\nInacalrura\nKusosaurus\nNdaaisaurus\nWtrokidor\nCaaerrae\nTosaurus\nAahus\nSichanoptosaurus\nAkropabrus\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 7800, Loss: 24.134288\n\nOnyusicherorus\nKlecalosaurus\nLytosaurus\nOkaagosaurus\nXusogophonyhosebrgimus\nEcaison\nTrolichiburosaurus\nAadosaurus\nSpendoraxaros\nAgrorachusanglus\n\n\nIteration: 7900, Loss: 24.119353\n\nOnvusaurus\nKlebamosaurus\nLxtosaurus\nOlaagosaurus\nXuspaogosaurus\nEdalosaurus\nTrolopronus\nA\nTolonosaurus\nAkprodandos\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 8000, Loss: 24.080356\n\nOnyus\nLoga\nLyusanonosaurus\nOla\nYuspdonniangorratops\nEdalosaurus\nTrohonggdyloscarosaurus\nA\nTolonis\nAgrus\n\n\nIteration: 8100, Loss: 23.977684\n\nOmusisaurus\nLleaagps\nLyusochinilus\nOgaagrracarretan\nXuspblasaurus\nEcairopa\nTrochesaurus\nAacosaurus\nSlbicioitasaurus\nAhpsaiasthucenus\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 8200, Loss: 24.001323\n\nOnyusfchenogurusmapilhtochustelamaguia\nLogcalosaurus\nLwusochinidynosaurus\nOjaagtpodanthulenvilax\nXustaogosaurus\nEeaesiddentesaurus\nTrodomnonusaurosaurus\nAaessalcisaurus\nTogodon\nAjrolbantitan\n\n\nIteration: 8300, Loss: 23.961329\n\nNivusbaneshaurosharinitochoqyllaramucenatia\nJmacakrona\nKwtrohicosaurus\nNgaaiselaastesaurus\nXussaurus\nDaaisig\nTrodomosaurus\nAagssalastes\nTohiaosaurus\nAiton\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 8400, Loss: 23.930120\n\nOnyusceratoptititaponitocitavifanbes\nKoia\nLytrodon\nOlaahus\nXustaneromuptosaurus\nDabarun\nTrocepsanykurucongitocluskelamelue\nAagstehanus\nTodomtiaumus\nAktria\n\n\nIteration: 8500, Loss: 23.900740\n\nOnwusaurus\nLice\nLytosaurus\nOla\nXuspendopavisaurus\nEdagosaurus\nTrodom\nAafron\nTodon\nAlosaurus\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 8600, Loss: 23.913945\n\nOnyusaurus\nLmcecersaumus\nLyusocidon\nOka\nXusraoereius\nDaadropacosaurus\nTrodon\nA\nSodrisaurus\nAisthachus\n\n\nIteration: 8700, Loss: 23.913765\n\nOnyusaurus\nLogealosaurus\nLyusaurus\nOma\nXusrangosaurus\nDaahosaurus\nTrodon\nA\nTolohopeus\nAlosaurus\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 8800, Loss: 23.906098\n\nOnvusaurus\nKidaahus\nLustolomopeus\nOla\nWtroeolopeus\nDaagosaurus\nTroeolopeus\nAahppelasops\nSpenatops\nAitona\n\n\nIteration: 8900, Loss: 23.842288\n\nPhvosaurus\nLica\nLustomicisaurus\nPedalosaurus\nXustarasaurus\nEcalosaurus\nTroglbosaurus\nA\nTolichkatasaurus\nAgropachus\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 9000, Loss: 23.908986\n\nOnvuscepernaviscocnideshamphykechaitan\nKlecalosaurus\nLyusicheosaurus\nOka\nXustandor\nEdaismedanosenenvngax\nTrodongolupsis\nA\nSpendor\nAgrteg\n\n\nIteration: 9100, Loss: 23.898281\n\nNixporangosaurus\nJibaagosaurus\nKwrosaurus\nNebaerona\nXusoeodon\nDaaerona\nTrodonosaurus\nAaforadantosaurus\nSichanolupnosaurus\nAisona\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 9200, Loss: 23.832290\n\nNixosaurus\nKiecaisieianosaurus\nKvrosaurus\nOlaagosaurus\nXstomomosaurus\nEdaerria\nTroinisaurus\nAagosaurus\nSkeripieurosaurus\nAisoka\n\n\nIteration: 9300, Loss: 23.795857\n\nNgyusicheroptosaurus\nKigaagps\nLyusicheroptosaurus\nNfa\nXusocelosaurus\nDaaersagaptosaurus\nTrohelosaurus\nA\nSicheroptosaurus\nAgrus\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 9400, Loss: 23.794542\n\nNgytotan\nJicabator\nKutosaurus\nNgaaeroracitatinevonax\nXutolodon\nDaaerrae\nTotaratops\nAaerradanosaurus\nTiengosaurus\nAhosaurus\n\n\nIteration: 9500, Loss: 23.774734\n\nNixspolonosaurus\nJicabasceia\nKytrokheosaurus\nOia\nYusoionosaurus\nDaaeror\nTrodon\nA\nTolomis\nAhosaurus\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 9600, Loss: 23.691922\n\nOlustolnctorsaurulophhus\nLlebalosaurus\nLyusraomiraverataurus\nOlaalosaurus\nXustarasaurus\nEdalosaurus\nTrodicholus\nAagptemastitalithelx\nTlengtinus\nAkosaurus\n\n\nIteration: 9700, Loss: 23.704882\n\nNgytosaurus\nJicabaspegaptor\nKystohoeronykurocophosaurus\nNgabertacaropterewmedyeimucetosaurus\nXtosaurus\nDaaersaichumuganuriaveoptagus\nTroceiniaunorocophitochurymeanghucenatia\nA\nTodngromulusharcenrtaropulecheitancapa\nAfppeechus\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 9800, Loss: 23.704355\n\nOnyusaurus\nKidabasibachunopelus\nLyustangosaurus\nOgaaisig\nXustaomingyiros\nEcalosaurus\nTrodomimathops\nA\nTodolosaurus\nAgrondaroptenothegybanteisaurus\n\n\nIteration: 9900, Loss: 23.673395\n\nOnyusidilus\nLnecalosaurus\nLytrraterhatasaurus\nOlabastelasimus\nXutolonosaurus\nEeaislla\nTrokilus\nAahusan\nTolomosaurus\nAltrmacisaurus\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10000, Loss: 23.658277\n\nOnyushanchogus\nKidabasmbabltesaurus\nLyusrapkorax\nOlaagrsaeeptosaurus\nXusraphorax\nDaagosaurus\nTrodolosaurus\nAaersalaptos\nSpandondylus\nAlpsalaptos\n\n\nIteration: 10100, Loss: 23.580777\n\nNgysspendondylus\nLlca\nLwtosaurus\nNgaagosatersaurus\nXusodongolus\nEdakptodan\nTrodomingwanns\nAagosan\nTodonipethosebrgimus\nAlosan\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10200, Loss: 23.671291\n\nNgytosaurus\nInbaahosaurus\nJwrosaurus\nNebahosaurus\nXusodonosaurus\nCaagosaurus\nTroeolosaurus\nA\nSkandosaurus\nAisonacosaurus\n\n\nIteration: 10300, Loss: 23.649617\n\nOnyushanasegulosaurus\nLlbaaerradantosaurus\nLxstogokosaurus\nOlaagosaurus\nXuspcheopevesaurus\nEcaklona\nTrodoloravipis\nA\nTreolopevesaurus\nAjpsagaptosaurus\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10400, Loss: 23.612724\n\nOnyuscepenomunsauirenismakulyelan\nLlecalosaurus\nLyushalapheuroskangomosaurus\nOjaaerphaceratops\nXustaneosaurus\nEcalosaurus\nTrochesaurus\nA\nTodongleveoscapkolus\nAdrrceentosaurus\n\n\nIteration: 10500, Loss: 23.642529\n\nOnxusidonosaurus\nLlee\nLytrolophoeverataus\nOla\nXussangosaurus\nEeagosaurus\nTrofngosaurus\nAahosaurus\nTrephorax\nAkropebptosaurus\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10600, Loss: 23.676895\n\nNgytosaurus\nKlcaafroodanthsaurus\nKvrosaurus\nNecakosaurus\nXustaolosaurus\nEcalspegchuosaurus\nTrocheosaurus\nA\nSpdidonaveritaurnitochustanamagtama\nAgssakaptosaurus\n\n\nIteration: 10700, Loss: 23.614322\n\nMeuskomomingyktos\nInde\nKussiandoraveros\nNdaakrosaurus\nWusochisaurus\nCaadropcarsaurus\nTroenasaurus\nA\nSlanesaurus\nAkron\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10800, Loss: 23.575651\n\nOnyusanomingycosaurus\nKlecalosaurus\nLytrong\nOlaahus\nXusodonosaurus\nEdaisilachusaleotonax\nTrodonroptisaurus\nAahosaurus\nSodomoraxasis\nAkrona\n\n\nIteration: 10900, Loss: 23.559830\n\nNgysroineosaurus\nInca\nKuspolnerostepsmarangrochusthiahelucheangalodor\nNecalosaurus\nXuslaneroptor\nDaaclpcaansaurus\nTrocheniasaururus\nAacosaurus\nSlanchoiteritaus\nAgosaurus\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 11000, Loss: 23.550267\n\nOnyusalolkonus\nLledalosaurus\nLxustaomingyerosaurus\nOjaaesraedosaurus\nXustarinonurosiarosauraptothia\nEdalosaurus\nTrodonjurus\nAahosaurus\nTrephorex\nAitorabosaurus\n\n\nIteration: 11100, Loss: 23.516143\n\nPhyusbaoforaxaurugosaurus\nLlecalosaurus\nLyusiangsfcterosaurus\nPeeaeptae\nYusodon\nEcalosaurus\nTrocemathus\nAadosaurus\nTrengosaurus\nAgpsamansaurus\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 11200, Loss: 23.467664\n\nMevrosaurus\nImacalosaurus\nJvosichia\nMacagosaurus\nXtkodia\nCaacosaurus\nTnpanasaurus\nAacltag\nTidelosaurus\nAfnsaurus\n\n\nIteration: 11300, Loss: 23.467676\n\nOmustoigannhyksaurus\nJicabasidadis\nLvushandoraxhosaurus\nOfaahus\nXustaparomunosaurus\nEcaipsan\nTrocheps\nAadrona\nTkgiaqolurops\nAhpsalaptosaurus\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 11400, Loss: 23.362778\n\nOnyusaurus\nLodaa\nLyusedleriaursmtatandrobiphyleamakuaicana\nOla\nXuspanchiaumorrasaurus\nEdaisphachusatroton\nTroceinonus\nA\nTrchanlatasaurus\nAkps\n\n\nIteration: 11500, Loss: 23.406335\n\nOnyus\nKlecalosaurus\nLytrodon\nOibaiptodanoptelotophya\nXusodon\nEdadosaurus\nTrochesaurus\nA\nTodolosaurus\nAgosaurus\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 11600, Loss: 23.299621\n\nMewtosaurus\nInedalosaurus\nJwprodolosaurus\nMacaiosaurus\nXusoeratogyenotaurus\nCaaerracblops\nTrodolosaurus\nAagosaurus\nTodolosaurus\nAlosaurus\n\n\nIteration: 11700, Loss: 23.376033\n\nNgysosaurus\nJiadantopaclus\nKusosaurus\nNdabasiceentosaurus\nXusnchapnitan\nCabarorachus\nTrodon\nA\nSkanciomurusabranisanmus\nAlnona\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 11800, Loss: 23.375660\n\nOnyus\nLoha\nLusptaomoravergtatorispanshyllaodosaurus\nOla\nXusokonosaurus\nEeahosaurus\nTrodomosaurus\nA\nTriomosaurus\nAlosaurus\n\n\nIteration: 11900, Loss: 23.395569\n\nNiwtosaurus\nKlecalosaurus\nLustolonlomuntisaurus\nOla\nXusteratops\nEcalosaurus\nTrocheriateraterenitocjusthechelukelasaurus\nAahosaurus\nTolodon\nAdromachus\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 12000, Loss: 23.401574\n\nOnvus\nLlee\nLvrosaurus\nOlabhosaurus\nXusolomingumostarbimus\nEdamosaurus\nTrodon\nA\nTriomondyopos\nAhpoledosaurus\n\n\nIteration: 12100, Loss: 23.432541\n\nNgyusegicinaverataus\nKlaca\nKvusianashcreshodon\nNgaagosaurus\nXusrandosaurus\nEgagosaurus\nTrodonathus\nAahus\nTraolosaurus\nAkrona\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 12200, Loss: 23.455520\n\nNgytosaurus\nKlaaajosaurus\nKvspolonhiaulosia\nNgaagosaurus\nXusociankatdosaurus\nDaaisolabnoptianticavantodauton\nTrocharkatatot\nAahosaurus\nToimapteulosdankantoansaurur\nAkpriaantatdiausaurus\n\n\nIteration: 12300, Loss: 23.405311\n\nNgytrong\nJiefalosaurus\nKussolophus\nNgaaishgdantosaurus\nWtrolonosaurus\nDaalosaurus\nTrokleroptisaurus\nAahsria\nToileronthoroclosaurans\nAkrona\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 12400, Loss: 23.405123\n\nOnyusanonosaurus\nLlecalosaurus\nLyusegolionylusanophesobisaurus\nOia\nXusojichicurosaurus\nEcalosaurus\nTroinesastis\nAacosaurus\nTrerasaurus\nAgrria\n\n\nIteration: 12500, Loss: 23.348174\n\nNgystongborawkustapnosaupus\nKilabasteedites\nLvosegnatikus\nNgaalosaurus\nXtosaurus\nEgalosaurus\nTrong\nAakosaurus\nTkengsaurus\nAlosapeosaurus\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 12600, Loss: 23.370081\n\nOnyusia\nKleaagosaurus\nLyustangosaurus\nOgaagsmeeanoponemus\nXustangosaurus\nDaaiska\nTrocelosaurus\nA\nTogolopewatotatops\nAgrtae\n\n\nIteration: 12700, Loss: 23.268727\n\nNixosaurus\nKohaaersalepsaurus\nLutosaurus\nNgbaisig\nXuspangosaurus\nEdaishhachurongithodychus\nTrochepicurosaurus\nA\nTogodopeurus\nAgrokachus\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 12800, Loss: 23.262121\n\nOlvpsaurus\nLledaltor\nLvpsodngsaurus\nOicalus\nWusteratops\nEebersaurus\nTrodon\nA\nToiojosaurus\nAitpracosaurus\n\n\nIteration: 12900, Loss: 23.223901\n\nNgxtosaurus\nKndaagosaurus\nLvpsedomanfus\nNgbalosaurus\nXusolonosaurus\nEcamitol\nTrodomosaurus\nAagosaurus\nTrchaoravlosaurus\nAgronderthollotia\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 13000, Loss: 23.237595\n\nOnyus\nLoha\nLytrokolsaurus\nOlabastei\nXuspaqcmokykus\nEeagosaurus\nTrodon\nAagrrhaceratops\nTrinhoravermtaus\nAkromabus\n\n\nIteration: 13100, Loss: 23.184493\n\nOnwusaurus\nJicabasila\nKvosaurus\nOlabbosaurus\nXsrocilosaurus\nEdagosaurus\nTrodonosaurus\nAagosaurus\nTididon\nAlosaurus\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 13200, Loss: 23.239143\n\nNgysprandondylus\nKlacaltor\nKyssranchiaukras\nNdaadrolacisaurus\nXuskararegveretasaurus\nCaacrodacosaurus\nTrocheriathors\nAacrodcarsaurus\nTrandondylus\nAisracantholentodex\n\n\nIteration: 13300, Loss: 23.272339\n\nOnyusaurus\nLogeagrope\nLystoloptopteryx\nOlaagosaurus\nXusojnerorumorucordosanosaurus\nEdalosaurus\nTrodoniceurosrangontochuspleanchuhamanfamumus\nAaispelaslisaurus\nTrephosaurus\nAgosaurus\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 13400, Loss: 23.282497\n\nNhytosaurus\nInecalptojantosaurus\nKustraphoraveriteratops\nNecalosaurus\nXustereps\nDabaspegceratops\nTrocheps\nAaersaocothurcethelya\nTrephordus\nAgrole\n\n\nIteration: 13500, Loss: 23.236782\n\nOlustolilosaurus\nLlecalosaurus\nLustolonholus\nOlaberosaurus\nXustangosaurus\nEgahosaurus\nTrocheosaurus\nAakosaurus\nTohleosaurus\nAhosaurus\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 13600, Loss: 23.267645\n\nNgysos\nKleeahosaurus\nKwrosaurus\nNgaaischachynsaurus\nXproinasaurus\nEfakosaurus\nTrofoniraurus\nAalosaurus\nSkeonosaurus\nAisrceerphomenus\n\n\nIteration: 13700, Loss: 23.294377\n\nNgysosaurus\nKolacerosaurus\nLxpprosaurus\nNgaaerrabaptor\nXusognatoptititan\nEgagosaurus\nTroinatorosaurus\nAajosaurus\nTrephosaurus\nAkropacisaurus\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 13800, Loss: 23.278406\n\nMivuscephorex\nInfa\nKyspodonkonyirosaurus\nMebaeosaurus\nXtroenesaurus\nEdaeosaurus\nTrodonosaurus\nAahosaurus\nSochisaurus\nAgosaurus\n\n\nIteration: 13900, Loss: 23.246274\n\nNgyskogia\nJidabasia\nKxprokekosaurus\nNebainona\nXsplanglomterosaurus\nDaaeropaantesaurus\nTroices\nAaeropachus\nSicheptetchosaurus\nAjloma\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 14000, Loss: 23.245061\n\nNgystog\nJlecalosaurus\nKusosaurus\nNgabeosaurus\nWurocheosaurus\nEdanosaurus\nTrocheosaurus\nAagosaurus\nToencincs\nAhosaurus\n\n\nIteration: 14100, Loss: 23.272506\n\nOmvosaurus\nLlee\nLystolommodus\nOlabeskhebntiten\nXusolominaurus\nEeahosaurus\nTroinasaurus\nAaerria\nTriolosaurus\nAisphadosaurus\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 14200, Loss: 23.174705\n\nOlustollerhathosaurus\nKldaalosaurus\nLwtotapnosaurus\nOfaadroracrus\nXuspancjomurosaurus\nEdaesmeiahonsaurus\nTrocenosaurus\nAacosaurus\nTreonnosshoro\nAgosaurus\n\n\nIteration: 14300, Loss: 23.152845\n\nMevrrodillojuporochus\nJicaceron\nKustolophusacrosaurus\nMacagps\nWurocephodyltos\nDaacosaurus\nTrocenltaurus\nAaciraebptosaurus\nTrephopaurosaurus\nAerria\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 14400, Loss: 23.095470\n\nMgyusaurus\nJjcaalosaurus\nKyusaurus\nMacalosaurus\nXustandon\nDaalosaurus\nTrodon\nAagosaurus\nTreonis\nAgpsan\n\n\nIteration: 14500, Loss: 23.111581\n\nNgytropigsanthorratiosaurus\nIndaberthachus\nKytronomoraverrtasaurus\nNgaaisrna\nXustangosaurus\nEeairria\nTrohianiaterotausaururus\nAagropachus\nTrchapriterntatilitochustonangitan\nAlronechusaurus\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 14600, Loss: 23.096725\n\nMevusaurus\nInbaalus\nIustrephosaurus\nMacalosaurus\nXustandopaverhuchibesmamurymachahua\nDaalosaurus\nTrodon\nAadrrahanus\nTreonosaurus\nAlosaurus\n\n\nIteration: 14700, Loss: 23.005313\n\nMevrosaurus\nInbaakosaurus\nKysosaurus\nMacalosaurus\nXusogonosaurus\nEeagosaurus\nTrodondosteros\nA\nSokolosaurus\nAlosaurus\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 14800, Loss: 23.123995\n\nMewtosaurus\nImacallthaclus\nIvuscepasceueoscaphikus\nMacagnonaclus\nXrlichasausaurupsaurus\nCaadosaunus\nTrochasausaurus\nA\nTochasaus\nAgnodecites\n\n\nIteration: 14900, Loss: 23.077141\n\nNgytosaurus\nJicabatorahosaurus\nLystoincosaurus\nNgaahotelaspksajitilawa\nXusolonisaurus\nDaaissan\nTrodontoosaurus\nAaesteianshuellus\nTreposaurus\nAgosaurus\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 15000, Loss: 23.128493\n\nNgytosaurus\nJolaagosaurus\nKustolong\nNecanosaurus\nXussaurus\nDaalosaurus\nTrochesaurus\nAalosaurus\nTollerkauprosaurus\nAgosaurus\n\n\nIteration: 15100, Loss: 23.130616\n\nNgytosaurus\nKola\nLvotom\nNgaaesaurus\nXustaodon\nEgagosaurus\nTrodon\nAaisaurus\nTraolosaurus\nAlosaurus\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 15200, Loss: 23.211378\n\nNgytosaurus\nKolebesra\nKyrspandynathospandonsocosaurus\nNgcalosaurus\nWusraonineuroshangilus\nEgagosaurus\nTrodon\nA\nTrephosaurus\nAgrrhados\n\n\nIteration: 15300, Loss: 23.204791\n\nMgwusaurus\nInedalosaurus\nIutosaurus\nMacalsica\nWuspandtonylus\nCaakron\nTrognatoptitosaurus\nA\nToholosaurus\nAissagnosaurus\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 15400, Loss: 23.155657\n\nMgyushandosaurus\nInecaesteia\nKvushandosaurus\nNgaafropa\nWuromeitheusistaplilus\nEdaispha\nTrongerngushis\nA\nTodolosaurus\nAgrus\n\n\nIteration: 15500, Loss: 23.148192\n\nNgystononosaurus\nJiecanrria\nKustonnbordyntosaurus\nNgaaersalchretan\nWusparchiaurus\nEdalosaurus\nTrongernatlosaurus\nAadropcarthranius\nTokleriasaurus\nAitorachus\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 15600, Loss: 23.162130\n\nOnyvromelus\nKlecanotelatops\nLutrodon\nOlabestelatops\nXuspeogosaurus\nEfaisina\nTrodon\nAaersalersaurus\nTrerasaurus\nAkrona\n\n\nIteration: 15700, Loss: 23.106350\n\nOmustolimis\nLlebaeosaurus\nLyrspandos\nOldalosaurus\nYuslengropterrochellos\nEeaeosaurus\nTrodelosaurus\nAaersaterylomelus\nTreolis\nAlosaurus\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 15800, Loss: 23.075693\n\nMeusosaurus\nJiabalosaurus\nKxus\nMacalosaurus\nXusolia\nEgagosaurus\nTrodleramunrnochelisaurus\nAadrs\nTodon\nAkosaurus\n\n\nIteration: 15900, Loss: 23.073658\n\nMevusarngsaurus\nImacaisauronsaurus\nJustognatoptlops\nMacaerradantosaurus\nXuspcheoraviosaurus\nDaadosaurus\nTroceratosaurus\nAacosaurus\nTkendoraviosaurus\nAgosaurus\n\n\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters, iteration, losses = model(data, ix_to_char, char_to_ix)\n",
    "plt.plot(iteration, losses)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Iteration')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "nlp-sequence-models",
   "graded_item_id": "1dYg0",
   "launcher_item_id": "MLhxP"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
